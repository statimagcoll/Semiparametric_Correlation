---
title: "ABCD Ridge-Ridge Simulations"
date: "`r Sys.Date()`"
output:
  html_document: 
    code_folding: hide
    toc: true
    toc_float: true
    number_sections: true
    theme: spacelab
    highlight: haddock
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, eval = TRUE)
```

These simulations are for Figures S1 and S3.

In this simulation, $\xi$ is equal to $\mu$, leading to 3 parameters.

$\xi$ and $\mu$ are cross-validated ridge regression.

We compare 4 ground truth values for "rho_true" (MPA) (0.1, 0.25, 0.5, 0.75) across a range of sample sizes with 500 simulations.


# Set up

```{r, eval=T}
# load libraries, data, and functions
source("/media/disk2/multivariateBWAS/ABCD_sims/ROI_sims/sim_setup_roi_ABCD.R")

# lambda grid for ridge regression
lambda_seq <- c(
  seq(10, 1, -1),        # From 10 to 1 (step of 1)
  seq(0.9, 0.1, -0.1),   # From 0.9 to 0.1 (step of 0.1)
  seq(0.09, 0.01, -0.01),# From 0.09 to 0.01 (step of 0.01)
  seq(0.009, 0.001, -0.001), # From 0.009 to 0.001 (step of 0.001)
  seq(0.0009, 0.0001, -0.0001), # From 0.0009 to 0.0001 (step of 0.0001)
  seq(0.00009, 0.00001, -0.00001), # From 0.00009 to 0.00001
  seq(0.000009, 0.000001, -0.000001), # From 0.000009 to 0.000001
  seq(0.0000009, 0.0000001, -0.0000001), # From 0.0000009 to 0.0000001
  0
)

rhos <- c(.10, .25, .50, .75)
ns <- c(100, 200, 500, 750, 1000, 1500, 2000, 3000, 4000, 5000, 6000, 7500, 10000, 20000)

# set number of simulations
nsim = 500

RNGkind("L'Ecuyer-CMRG") # for reproducibility with pbmclapply
seed_table = data.frame(build = c(123, 435, 300, 789, 900), sim = c(029, 866, 999, 013, 456))
```


```{r}
# function to take phenotype, rho_true, seed index, arguments for sim function
perform_sim = function(pheno, rho_true, seed_ind, ncores, ...){
  # set path for results
  results_path = paste0("/media/disk2/multivariateBWAS/ABCD_sims/ROI_sims/results/harmonized/ridge_build/", pheno, "/")
  # create results subfolders if needed
  check_dirs(results_path, rhos, ns)
  
  # build model
  # cross-validated ridge regression
  keep_inds = which(!(is.na(build[,pheno])))
  ridgeModel = cv.glmnet(x=build[keep_inds, "img"], y=build[keep_inds, pheno], alpha = 0, lambda = lambda_seq)
  # save "true" lambda value
  true_lambda = ridgeModel$lambda.min
  
  saveRDS(true_lambda, paste0(results_path, "rho_", rho_true*100, "/true_lambda.rds"))
  
  # get oob residuals that will be the error distribution for the eval data
  res = as.vector(build[keep_inds, pheno] - predict(ridgeModel, newx=build[keep_inds, "img"], s="lambda.min")) # xx I should be keeping this the same for all rhos 
  # calculate xi(X) in the eval pop - double checked the fakeYmean though and it looks the same across settings so I think it is okay
  eval$fakeYMean = predict(ridgeModel, newx=eval$img, s="lambda.min")
  
  # save fakeYMean
  saveRDS(eval$fakeYMean, paste0(results_path, "rho_", rho_true*100,"/fakeYMean.rds"))
  
  # variance of xi is the same across sims, just changing the variance of Y via the error
  v_xi = var(eval$fakeYMean)
  
  # set target rho_true and get smooth distribution of the residuals
  ls_res = logspline_targetrho(res, eval$fakeYMean, rho_true) 
  
  # save error distribution
  saveRDS(ls_res, paste0(results_path, "rho_", rho_true*100, "/ls_res.rds"))
  
  # get properties of the error distribution
  rho_res = get_rho_ls(eval$fakeYMean, ls_res)
  
  eval$mu = eval$fakeYMean
  
  # for rho_2, fit a model outside of the simulations
  eval_train$fakeYMean = predict(ridgeModel, newx=eval_train$img, s="lambda.min")
  eval_test$fakeYMean = predict(ridgeModel, newx=eval_test$img, s="lambda.min")
  eval_train$fakeY = eval_train$fakeYMean + rlogspline(nrow(eval_train), ls_res) - rho_res$mean_res
  muhat_tr_mod = cv.glmnet(x = eval_train$img, y = eval_train$fakeY, alpha = 0, lambda = lambda_seq)
  
  # for reproducibility using pbmclapply
  set.seed(seed_table$sim[seed_ind])
  mc.reset.stream()
  
  # perform sims
  sim_IF_3param(dt = eval, model_func = cv.glmnet, xi_name = "fakeYMean", ls_dist = ls_res, res_mean = rho_res$mean_res,
         res_var = rho_res$v_res, rho_2_test_dat = eval_test, ns = ns, nsim = nsim, K = 5, xname = "img",
         yname = "fakeY", model_args = list(alpha = 0, lambda = lambda_seq), types = all_types,
         cf_method = c("instant", "hold"),
         save_path = paste0(results_path, "rho_", rho_true*100, "/n"), ncores = ncores, muhat_tr_mod = muhat_tr_mod)
}

```


# Build

```{r, eval=T}
seed_ind = 1
saveRDS(seed_ind, paste0("/media/disk2/multivariateBWAS/ABCD_sims/ROI_sims/results/harmonized/ridge_build/", "seed_ind.rds"))
set.seed(seed_table$build[seed_ind]) 

dat_split = split_model(dat)
build = dat_split$d1
eval = dat_split$d2

rm(dat)
rm(dat_split)

# standardize X in build
x_means = colMeans(build$img)
x_sds = apply(build$img, 2, sd)
build$img = scale(build$img)
# apply same scaling to eval
eval$img = scale(eval$img, center = x_means, scale = x_sds)
# Standardize Y in build
build$age = scale(build$age)
build$fluid = scale(build$fluid)
build$depression = scale(build$depression)


# for rho_2, cor_n(muhat_tr(X_te), Y_te | muhat_tr), need to define a model to apply as given
# split so that the training model uses 500 people
eval_split = split_model(eval, prop=(nrow(eval)-500)/(nrow(eval)))
eval_train = eval_split$d2
eval_test = eval_split$d1
rm(eval_split)
```

# Simulations

```{r}
for (phen in c("age", "fluid", "depression")){
  for (rho in rhos){
    perform_sim(phen, rho, seed_ind, ncores = 32)
  }
}

```


```{r, eval=F}
knitr::purl("/media/disk2/multivariateBWAS/ABCD_sims/ROI_sims/ABCD_DK_ridge_sims.Rmd")
```
