---
title: "RBC Analysis Ridge Regression"
date: "`r Sys.Date()`"
output:
  html_document: 
    code_folding: hide
    toc: true
    toc_float: true
    number_sections: true
    theme: spacelab
    highlight: haddock
---

# Loading in Libraries

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(vtable)
library(knitr) 
library(glmnet)
library(locfit)
library(table1)
library(boot)
library(ggplot2)
library(GGally)
library(cowplot)
library(kableExtra)

# Setting the seed
set.seed(123)
```

# Loading in RBC and Functional Data

```{r}
# Loading in data
rbc <- read_csv("/media/disk2/RBC_version0.1/regional_GMV_all_sites_harmonized_covariates.csv")

# Reading in the structural data
func <- read_csv("/media/disk2/RBC_version0.1/FC_network17_harmonized_covariates.csv")

# Setting each dataset to only include patients that overlap 
rbc = rbc[rbc$participant_id %in% func$participant_id,]
func = func[func$participant_id %in% rbc$participant_id,]

# Sanity check
sum(rbc$participant_id == func$participant_id) == nrow(func)

# Merging datasets
cols_to_add <- setdiff(names(func), names(rbc))
both <- dplyr::inner_join(rbc, func[, c("participant_id", cols_to_add)], by = "participant_id")

# Changing sex to a binary - Male = 1; Female = 0
both = both %>% mutate(sex = ifelse(sex == "Male", 1, 0))

# Loading in functions
# Loading in functions
source("/media/disk2/multivariateBWAS/code_for_review/build_funcs.R")
# Sourcing influence and correlation functions
source("/media/disk2/multivariateBWAS/code_for_review/influence_funcs.R")
source("/media/disk2/multivariateBWAS/code_for_review/corr_funcs.R")

# Loading in color palette
cbbPalette <- c("#000000","#E69F00","#56B4E9","#009E73",
                "#F0E442","#0072B2","#D55E00","#CC79A7")
```

# Machine Learning Functions

## Bound Calculation and Output Functions 
```{r}
# Creating confidence interval function 
getBounds <- function(data, est, conf, influ, type, outcome){
  # Creating global variables
  cl = conf
  samp = nrow(data %>% drop_na(outcome))
  
  # Calculating OS estimator
  if(type == "One-Step"){
    # Calculating bounds
    LB_est = sqrt(expit(logit(est^2) - qnorm(cl + (1 - cl) / 2)*sqrt(var(influ)/samp)))
    UB_est = sqrt(expit(logit(est^2) - qnorm((1 - cl) / 2)*sqrt(var(influ)/samp)))
  }
  # Calculating Pearson
  else if(type == "Pearson"){
    # Calculating bounds
    LB_est = tanh(atanh(est) - qnorm(cl + (1-cl)/2) * (1/sqrt(samp - 3)))
    UB_est = tanh(atanh(est) - qnorm((1-cl)/2) * (1/sqrt(samp - 3)))
  }
  # Case if no type is recognized
  else{
    print("Applicable types of estimate not selected.")
  }
  return(c(LB_est, UB_est))
}




# Function to format results
out_frame <- function(pears, OS, pear_bounds, OS_bounds, outcome, influ, label = "Base"){
  data.frame(stat = c("Pearson", "One-Step"), 
             label = c(label, label),
             estimates = c(pears, OS),
             lower_bounds = c(pear_bounds[1], OS_bounds[1]),
             upper_bounds = c(pear_bounds[2], OS_bounds[2]),
             Inf_Vec = I(list(influ, influ)), 
             ScoreType = outcome)
}
```

## Getting OS Differences and Ratios
```{r}
# Getting the bounds and OS difference for an outcome variable 
# Outcome is the string name of the predicted variable
get_OS_diff <- function(OS_base, OS_struct, OS_func, OS_both, influ_base, influ_struct, influ_func, influ_both, outcome){
  # Calculating differences
  diff_struct <- cor_os_diff(OS_struct, OS_base, influ_struct, influ_base)
  diff_func <- cor_os_diff(OS_func, OS_base, influ_func, influ_base)
  diff_both <- cor_os_diff(OS_both, OS_base, influ_both, influ_base)
  
  # Converting differences to data frame
  diff_struct = data.frame(diff = diff_struct[1], lCI_diff = diff_struct[2], uCI_diff = diff_struct[3], outcome = outcome, Type = "Structural vs. Base")
  diff_func = data.frame(diff = diff_func[1], lCI_diff = diff_func[2], uCI_diff = diff_func[3], outcome = outcome, Type = "Functional vs. Base")
  diff_both = data.frame(diff = diff_both[1], lCI_diff = diff_both[2], uCI_diff = diff_both[3], outcome = outcome, Type = "Both vs. Base")
  
  # Combining all data together
  diff_all <- rbind(diff_struct, diff_func, diff_both)
  
  # Truncating to bounds of 2 and -2
  diff_all <- diff_all %>%
    mutate(lCI_diff = ifelse(lCI_diff < -2, -2, lCI_diff)) %>%
    mutate(uCI_diff = ifelse(uCI_diff > 2, 2, uCI_diff))
  
  # Getting rid of row names
  rownames(diff_all) <- NULL
  
  # Returning difference data frame
  return(diff_all)
}


# Getting the bounds and OS difference for an outcome variable 
# Outcome is the string name of the predicted variable
get_OS_ratio <- function(OS_base, OS_struct, OS_func, OS_both, influ_base, influ_struct, influ_func, influ_both, outcome){
  # Calculating differences
  ratio_struct <- cor_os_ratio(OS_struct, OS_base, influ_struct, influ_base)
  ratio_func <- cor_os_ratio(OS_func, OS_base, influ_func, influ_base)
  ratio_both <- cor_os_ratio(OS_both, OS_base, influ_both, influ_base)
  
  # Converting differences to data frame
  ratio_struct = data.frame(ratio = ratio_struct[1], lCI_ratio = ratio_struct[2], uCI_ratio = ratio_struct[3], outcome = outcome, Type = "Structural vs. Base")
  ratio_func = data.frame(ratio = ratio_func[1], lCI_ratio = ratio_func[2], uCI_ratio = ratio_func[3], outcome = outcome, Type = "Functional vs. Base")
  ratio_both = data.frame(ratio = ratio_both[1], lCI_ratio = ratio_both[2], uCI_ratio = ratio_both[3], outcome = outcome, Type = "Both vs. Base")
  
  # Combining all data together
  ratio_all <- rbind(ratio_struct, ratio_func, ratio_both)
  
  # Getting rid of row names
  rownames(ratio_all) <- NULL
  
  # Returning difference data frame
  return(ratio_all)
}
```

## Analysis and Sample Splitting Methods
```{r}
# Cross-Validation Function for RidgeRegression
RidgeCV <- function(data, folds, outcome, typeDat){
  # Cleaning data
  ## Data Processing - drop NA before CV
  data_clean = data %>% drop_na(outcome) 
  ## Assigning folds
  data_clean$fold <- sample(rep(1:folds, length.out = nrow(data_clean)))
  ## Checking for fold distribution 
  table(data_clean$fold)
  
  
  # Storage variables
  OS_estimator = c()
  pears_estimator = c()
  influ_res_out = vector("list", length = folds)
  lambda = c()
  
  # Creating a for loop for 5-fold cross validation
  for(i in 1:folds){
    # Assigning data
    test = data_clean %>% filter(fold == i)
    train = data_clean %>% filter(fold != i)
    
    # Assigning x and y 
    if(typeDat != "Baseline"){
      if(outcome == "age"){
        x_var = data.matrix(train[, grepl(typeDat, colnames(train)) | colnames(train) %in% c("sex", "euler", "meanFD")]) # can add euler here
        y_var = data.matrix(train[, outcome])
        newx = data.matrix(test[, grepl(typeDat, colnames(test)) | colnames(test) %in% c("sex", "euler", "meanFD")])
      }
      
      else{
        x_var = data.matrix(train[, grepl(typeDat, colnames(train)) | colnames(train) %in% c("age", "sex", "euler", "meanFD")])
        y_var = data.matrix(train[, outcome])
        newx = data.matrix(test[, grepl(typeDat, colnames(test)) | colnames(test) %in% c("age", "sex", "euler", "meanFD")])
      }
    }
    else{
      if(outcome == "age"){
        x_var = data.matrix(train[, colnames(train) %in% c("sex", "euler", "meanFD")])
        y_var = data.matrix(train[, outcome])
        newx = data.matrix(test[, colnames(test) %in% c("sex", "euler", "meanFD")])
      }
      
      else{
        x_var = data.matrix(train[, colnames(train) %in% c("age", "sex", "euler", "meanFD")])
        y_var = data.matrix(train[, outcome])
        newx = data.matrix(test[, colnames(test) %in% c("age", "sex", "euler", "meanFD")])
      }
    }
    
    # Fitting a ridge regression model
    lambda_seq <- c(
      seq(10, 1, -1),        # From 10 to 1 (step of 1)
      seq(0.9, 0.1, -0.1),   # From 0.9 to 0.1 (step of 0.1)
      seq(0.09, 0.01, -0.01),# From 0.09 to 0.01 (step of 0.01)
      seq(0.009, 0.001, -0.001), # From 0.009 to 0.001 (step of 0.001)
      seq(0.0009, 0.0001, -0.0001), # From 0.0009 to 0.0001 (step of 0.0001)
      seq(0.00009, 0.00001, -0.00001), # From 0.00009 to 0.00001
      seq(0.000009, 0.000001, -0.000001), # From 0.000009 to 0.000001
      seq(0.0000009, 0.0000001, -0.0000001), # From 0.0000009 to 0.0000001
      0
    )
    ridgeModel <- cv.glmnet(x_var, y_var, alpha = 0, lambda = lambda_seq)
    
    # Getting predictions
    test$preds = predict(ridgeModel, newx = newx, s = "lambda.min")
    
    # Storing minimum lambda used
    lambda = c(lambda, ridgeModel$lambda.min)
    
    # Formatting y and predictions for easier analysis
    mu = as.vector(test$preds)
    y_real = as.numeric(test[[outcome]])
    
    # Getting influence function vector on predicted y and y
    # pull from inluence_funcs - if_logit_sq (muhat is predicted y)
    inf_res = if_logit_sq(mu, y_real)
    influ_res_out[[i]] <- inf_res
    
    # Plotting a matrix of y_real, predictions, and the influence function
    # df <- data.frame(mu, y_real, inf_res)
    # pairs(df, main = paste(outcome, typeDat, "Fold", i))
    
    # Getting pearson estimator 
    pear_res = cor(mu, y_real)
    pears_estimator = c(pears_estimator, pear_res)
    
    # Getting one-step estimator; predictions are passed into the function first
    os_res = cor_os(mu, y_real)
    OS_estimator = c(OS_estimator, os_res)
  }
  
  # return(data.frame(OS_estimator, pears_estimator, lambda))
  influ_res_out = data.frame(influence_results = I(influ_res_out))
  return(data.frame(lambda, OS_estimator, pears_estimator, influ_res_out))
}


# Function for analysis without PCs
getAnalysis <- function(data, outcome, struct_string, func_string, folds, CI, label){
  # Collecting for no data 
  # Performing the cross-validation
  base <- RidgeCV(data, folds, outcome, "Baseline")
  
  # Take average of each estimator from cross-folds as final point estimate ("instant" cross-fitting)
  OS_base = mean(base$OS_estimator)
  pears_base = mean(base$pears_estimator)
  
  # Getting influence function output
  influ_res_base = c()
  for(i in 1:nrow(base)){
    influ_res_base = c(influ_res_base, base[[i,"influence_results"]])
  }
  
  # Getting bounds for One-Step
  OS_bounds_base = getBounds(data, OS_base, CI, influ_res_base, "One-Step", outcome)
  
  # Getting bounds for Pearson
  Pear_bounds_base = getBounds(data, pears_base, CI, influ_res_base, "Pearson", outcome)
  
  # Storing results in a data frame
  base_results <- out_frame(pears_base, OS_base, Pear_bounds_base, OS_bounds_base, label, influ_res_base)
  
  
  # Collecting for structural data
  # Performing the cross-validation
  struct <- RidgeCV(data, folds, outcome, struct_string)
  
  # Take average of each estimator from cross-folds as final point estimate ("instant" cross-fitting)
  OS_struct = mean(struct$OS_estimator)
  pears_struct = mean(struct$pears_estimator)
  
  # Getting influence function output
  influ_res_struct = c()
  for(i in 1:nrow(struct)){
    influ_res_struct = c(influ_res_struct, struct[[i,"influence_results"]])
  }
  
  # Getting bounds for One-Step
  OS_bounds_struct = getBounds(data, OS_struct, CI, influ_res_struct, "One-Step", outcome)
  
  # Getting bounds for Pearson
  Pear_bounds_struct = getBounds(data, pears_struct, CI, influ_res_struct, "Pearson", outcome)
  
  # Storing results in a data frame
  struct_results <- out_frame(pears_struct, OS_struct, Pear_bounds_struct, OS_bounds_struct, label, influ_res_struct, "Structural Data")
  
  
  
  # Collecting for functional data
  # Performing the cross-validation
  func <- RidgeCV(data, folds, outcome, func_string)
  
  # Take average of each estimator from cross-folds as final point estimate ("instant" cross-fitting)
  OS_func = mean(func$OS_estimator)
  pears_func = mean(func$pears_estimator)
  
  # Getting influence function output
  influ_res_func = c()
  for(i in 1:nrow(func)){
    influ_res_func = c(influ_res_func, func[[i,"influence_results"]])
  }
  
  # Getting bounds for One-Step
  OS_bounds_func = getBounds(data, OS_func, CI, influ_res_func, "One-Step", outcome)
  
  # Getting bounds for Pearson
  Pear_bounds_func = getBounds(data, pears_func, CI, influ_res_func, "Pearson", outcome)
  
  # Storing results in a data frame
  func_results <- out_frame(pears_func, OS_func, Pear_bounds_func, OS_bounds_func, label, influ_res_func, "Functional Data")
  
  
  
  # Collecting for both structural and functional data
  # Performing the cross-validation
  both <- RidgeCV(data, folds, outcome, paste0(struct_string,"|",func_string))
  
  # Take average of each estimator from cross-folds as final point estimate ("instant" cross-fitting)
  OS_both = mean(both$OS_estimator)
  pears_both = mean(both$pears_estimator)
  
  # Getting influence function output
  influ_res_both = c()
  for(i in 1:nrow(both)){
    influ_res_both = c(influ_res_both, both[[i,"influence_results"]])
  }
  
  # Getting bounds for One-Step
  OS_bounds_both = getBounds(data, OS_both, CI, influ_res_both, "One-Step", outcome)
  
  # Getting bounds for Pearson
  Pear_bounds_both = getBounds(data, pears_both, CI, influ_res_both, "Pearson", outcome)
  
  # Storing results in a data frame
  both_results <- out_frame(pears_both, OS_both, Pear_bounds_both, OS_bounds_both, label, influ_res_both, "Both")
  

  # Combining all datasets together for age
  results <- rbind(base_results, struct_results, func_results, both_results)
  return(results)
}


# Sample Split training sample 
getSampleSplit <- function(data, outcome, struct_string, func_string, folds, splits, CI, label){
  # Setting column names and storage for analysis 
  column_names <- c('stat', 'label', 'estimates', 'lower_bounds', 'upper_bounds', 'ScoreType', 'Split')
  results <- data.frame(matrix(ncol = length(column_names), nrow = 0, dimnames = list(NULL, column_names)))
  
  # Setting column names and storage for one-step estimator differences/ratios
  column_names_DR <- c('outcome', 'Type', 'ratio', 'lCI_ratio', 'uCI_ratio', 'diff', 'lCI_diff', 'uCI_diff')
  results_DR <- data.frame(matrix(ncol = length(column_names_DR), nrow = 0, dimnames = list(NULL, column_names_DR)))
  
  # Running the analysis
  while(splits > 0){ # Add split number here 
    # Storing analysis splits
    temp = getAnalysis(data, outcome, struct_string, func_string, folds, CI, label)
    temp$split = splits
    results <- rbind(results, temp)
    
    # Storing difference and ratio per split 
    diff <- get_OS_diff(temp$estimates[2], temp$estimates[4], temp$estimates[6], temp$estimates[8], temp$Inf_Vec[[2]], temp$Inf_Vec[[4]], temp$Inf_Vec[[6]], temp$Inf_Vec[[8]], outcome)
    ratio <- get_OS_ratio(temp$estimates[2], temp$estimates[4], temp$estimates[6], temp$estimates[8], temp$Inf_Vec[[2]], temp$Inf_Vec[[4]], temp$Inf_Vec[[6]], temp$Inf_Vec[[8]], outcome)
    temp_DR = merge(ratio, diff, by = c("outcome", "Type"))
    temp_DR$split = splits
    results_DR <- rbind(results_DR, temp_DR)

    # Subtracting split by 1
    splits = splits - 1
  }
  
  return(list(results, results_DR))
}
```


## Method for Ridge Regression with PCs
```{r}
# Ride Regression with PCs
RidgeCV_PC <- function(data, folds, outcome, typeDat, n_pcs){
  # Cleaning data
  data_clean = data %>% drop_na(outcome) 
  # Assigning folds
  data_clean$fold <- sample(rep(1:folds, length.out = nrow(data_clean)))
  # Checking for fold distribution 
  table(data_clean$fold)
  
  
  # Storage variables
  OS_estimator = c()
  pears_estimator = c()
  influ_res_out = vector("list", length = folds)
  lambda = c()
  # Creating a for loop for 5-fold cross validation
  for(i in 1:folds){
    # Assigning data
    test = data_clean %>% filter(fold == i)
    train = data_clean %>% filter(fold != i)
    
    # Assigning x and y 
    if(typeDat != "Baseline"){
      if(outcome == "age"){
        # Taking train and y data
        x_var_train = as.matrix(train[, grepl(typeDat, colnames(train))])
        y_var_train = as.matrix(train[,outcome])
        
        # Getting pcs for train data
        pc = prcomp(x_var_train, rank. = n_pcs)
        # Get latent representation for x_var_train
        princ_comps_train = predict(pc, x_var_train)
        
        # Store new training variable
        new_train = as.data.frame(cbind(princ_comps_train, as.data.frame(train[,colnames(train) %in% c("sex", "euler", "meanFD")])))
        new_train = as.matrix(new_train)
        
        
        # Getting pcs for test data
        x_var_test = as.matrix(test[,grepl(typeDat, colnames(test))])
        
        # Get latent representation for x_var_test
        princ_comps_test = predict(pc, x_var_test)
        
        # Form new test data
        new_test = as.data.frame(cbind(princ_comps_test, as.data.frame(test[,colnames(test) %in% c("euler", "meanFD", "sex")])))
        new_test = as.matrix(new_test)
      }
      else{
        # Taking train and y data
        x_var_train = as.matrix(train[, grepl(typeDat, colnames(train))])
        y_var_train = as.matrix(train[, outcome])
        
        # Getting pcs for train data
        pc = prcomp(x_var_train, rank. = n_pcs)
        # Get latent representation for x_var_train
        princ_comps_train = predict(pc, x_var_train)
        
        # Store new training variable
        new_train = as.data.frame(cbind(princ_comps_train, as.data.frame(train[,colnames(train) %in% c("age", "sex", "euler", "meanFD")])))
        new_train = as.matrix(new_train)
        
        
        # Getting pcs for test data
        x_var_test = as.matrix(test[,grepl(typeDat, colnames(test))])
        
        # Get latent representation for x_var_test
        princ_comps_test = predict(pc, x_var_test)
        
        # Form new test data
        new_test = as.data.frame(cbind(princ_comps_test, as.data.frame(test[,colnames(test) %in% c("age", "euler", "meanFD", "sex")])))
        new_test = as.matrix(new_test)
      }
    }
    else{
      if(outcome == "age"){
        new_train = data.matrix(train[, colnames(train) %in% c("sex", "euler", "meanFD")])
        y_var_train = data.matrix(train[, outcome])
        new_test = data.matrix(test[, colnames(test) %in% c("sex", "euler", "meanFD")])
      }
      
      else{
        new_train = data.matrix(train[, colnames(train) %in% c("age", "sex", "euler", "meanFD")])
        y_var_train = data.matrix(train[, outcome])
        new_test = data.matrix(test[, colnames(test) %in% c("age", "sex", "euler", "meanFD")])
      }
    }
    
    # Fitting a ridge regression model
    lambda_seq <- c(
      seq(10, 1, -1),        # From 10 to 1 (step of 1)
      seq(0.9, 0.1, -0.1),   # From 0.9 to 0.1 (step of 0.1)
      seq(0.09, 0.01, -0.01),# From 0.09 to 0.01 (step of 0.01)
      seq(0.009, 0.001, -0.001), # From 0.009 to 0.001 (step of 0.001)
      seq(0.0009, 0.0001, -0.0001), # From 0.0009 to 0.0001 (step of 0.0001)
      seq(0.00009, 0.00001, -0.00001), # From 0.00009 to 0.00001
      seq(0.000009, 0.000001, -0.000001), # From 0.000009 to 0.000001
      seq(0.0000009, 0.0000001, -0.0000001), # From 0.0000009 to 0.0000001
      0
    )
    ridgeModel <- cv.glmnet(new_train, y_var_train, alpha = 0, lambda = lambda_seq)
    
    # Getting predictions
    test$preds = predict(ridgeModel, newx = new_test, s = "lambda.min")
    
    # Storing minimum lambda used
    lambda = c(lambda, ridgeModel$lambda.min)
    
    # Formatting y and predictions for easier analysis
    mu = as.vector(test$preds)
    y_real = as.numeric(test[[outcome]])
    
    # Getting influence function vector on predicted y and y
    # pull from inluence_funcs - if_logit_sq (muhat is predicted y)
    inf_res = if_logit_sq(mu, y_real)
    influ_res_out[[i]] <- inf_res
    
    # Plotting a matrix of y_real, predictions, and the influence function
    # df <- data.frame(mu, y_real, inf_res)
    # pairs(df, main = paste(outcome, typeDat, "Fold", i))
    
    # Getting pearson estimator 
    pear_res = cor(mu, y_real)
    pears_estimator = c(pears_estimator, pear_res)
    
    # Getting one-step estimator; predictions are passed into the function first
    os_res = cor_os(mu, y_real)
    OS_estimator = c(OS_estimator, os_res)
  }
  
  # return(data.frame(OS_estimator, pears_estimator, lambda))
  influ_res_out = data.frame(influence_results = I(influ_res_out))
  return(data.frame(lambda, OS_estimator, pears_estimator, influ_res_out))
}
```

# Analyses with Functional, Structural, and Both Data with No PCs

## Performing Analysis on Age

```{r}
# Running Analyis
age_result = getSampleSplit(both, "age", "X17", "_to_", 5, 100, 0.95, "Age")

# Taking medians of each statistic in Age analysis
age_analysis_results = age_result[[1]] %>%
  group_by(stat, label) %>%
  summarise(
    lower_bounds = median(lower_bounds, na.rm = TRUE),
    upper_bounds = median(upper_bounds, na.rm = TRUE),
    estimates = median(estimates, na.rm = TRUE)
  )
age_analysis_results$ScoreType = "Age"


# Taking medians of each statistic in OS diff/ratio scores for age
age_DR_results = age_result[[2]] %>%
  group_by(Type) %>%
  summarise(
    ratio = median(ratio, na.rm = TRUE),
    lCI_ratio = median(lCI_ratio, na.rm = TRUE),
    uCI_ratio = median(uCI_ratio, na.rm = TRUE),
    diff = median(diff, na.rm = TRUE),
    lCI_diff = median(lCI_diff, na.rm = TRUE),
    uCI_diff = median(uCI_diff, na.rm = TRUE)
  )
age_DR_results$ScoreType = "Age"
```

## Performing Analysis on P-Factor

```{r}
# Running analysis 
pfac_result = getSampleSplit(both, "p_factor_mcelroy_harmonized_all_samples", "X17", "_to_", 5, 100, 0.95, "P-Factor")

# Taking medians of each statistics
pfac_analysis_results = pfac_result[[1]] %>%
  group_by(stat, label) %>%
  summarise(
    lower_bounds = median(lower_bounds, na.rm = TRUE),
    upper_bounds = median(upper_bounds, na.rm = TRUE),
    estimates = median(estimates, na.rm = TRUE)
  )
pfac_analysis_results$ScoreType = "P-Factor"

# Taking medians of each statistic in OS diff/ratio scores for age
pfac_DR_results = pfac_result[[2]] %>%
  group_by(Type) %>%
  summarise(
    ratio = median(ratio, na.rm = TRUE),
    lCI_ratio = median(lCI_ratio, na.rm = TRUE),
    uCI_ratio = median(uCI_ratio, na.rm = TRUE),
    diff = median(diff, na.rm = TRUE),
    lCI_diff = median(lCI_diff, na.rm = TRUE),
    uCI_diff = median(uCI_diff, na.rm = TRUE)
  )
pfac_DR_results$ScoreType = "P-Factor"
```

## Performing Analysis on Internalizing

```{r}
# Running analysis 
int_result = getSampleSplit(both, "internalizing_mcelroy_harmonized_all_samples", "X17", "_to_", 5, 100, 0.95, "Internalizing Score")

# Taking medians of each statistics
int_analysis_results = int_result[[1]] %>%
  group_by(stat, label) %>%
  summarise(
    lower_bounds = median(lower_bounds, na.rm = TRUE),
    upper_bounds = median(upper_bounds, na.rm = TRUE),
    estimates = median(estimates, na.rm = TRUE)
  )
int_analysis_results$ScoreType = "Internalizing Score"

# Taking medians of each statistic in OS diff/ratio scores for age
int_DR_results = int_result[[2]] %>%
  group_by(Type) %>%
  summarise(
    ratio = median(ratio, na.rm = TRUE),
    lCI_ratio = median(lCI_ratio, na.rm = TRUE),
    uCI_ratio = median(uCI_ratio, na.rm = TRUE),
    diff = median(diff, na.rm = TRUE),
    lCI_diff = median(lCI_diff, na.rm = TRUE),
    uCI_diff = median(uCI_diff, na.rm = TRUE)
  )
int_DR_results$ScoreType = "Internalizing Score"
```

## Performing Analysis on Externalizing
```{r}
# Running analysis 
ext_result = getSampleSplit(both, "externalizing_mcelroy_harmonized_all_samples", "X17", "_to_", 5, 100, 0.95, "Externalizing Score")

# Taking medians of each statistics
ext_analysis_results = ext_result[[1]] %>%
  group_by(stat, label) %>%
  summarise(
    lower_bounds = median(lower_bounds, na.rm = TRUE),
    upper_bounds = median(upper_bounds, na.rm = TRUE),
    estimates = median(estimates, na.rm = TRUE)
  )
ext_analysis_results$ScoreType = "Externalizing Score"

# Taking medians of each statistic in OS diff/ratio scores for age
ext_DR_results = ext_result[[2]] %>%
  group_by(Type) %>%
  summarise(
    ratio = median(ratio, na.rm = TRUE),
    lCI_ratio = median(lCI_ratio, na.rm = TRUE),
    uCI_ratio = median(uCI_ratio, na.rm = TRUE),
    diff = median(diff, na.rm = TRUE),
    lCI_diff = median(lCI_diff, na.rm = TRUE),
    uCI_diff = median(uCI_diff, na.rm = TRUE)
  )
ext_DR_results$ScoreType = "Externalizing Score"
```

# Graphing Results

## Graphing Correlation Results

```{r}
# Combining results for both outcomes
results <- rbind(age_analysis_results, pfac_analysis_results, int_analysis_results, ext_analysis_results)

# Reorder the x-axis ticks
results$label <- factor(results$label,
                        levels = c("Base", "Structural Data", "Functional Data", "Both"))

# Reorder the legend (and plotting order) so Pearson comes first
results$stat <- factor(results$stat,
                       levels = c("Pearson", "One-Step"))

# Setting order of boxes
results$ScoreType <- factor(results$ScoreType,
                            levels = c("Age", "P-Factor", "Externalizing Score", "Internalizing Score"))

# Graphing Results
corr_results <- ggplot(results, aes(x = label, y = estimates, color = stat)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(ymin = lower_bounds, ymax = upper_bounds),
                width = 0.2,
                position = position_dodge(width = 0.5)) +
  facet_wrap(~ ScoreType, nrow = 1) +  # or facet_grid(~ ScoreType)
  labs(title = "Ridge Regression Analysis of Outcomes in RBC",
       x = "Model Features",
       y = "Correlation",
       color = "Estimator") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust=1)) + 
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") + 
  scale_color_manual(values = c("One-Step" = "#56B4E9",
                                "Pearson" = "#D55E00"))
corr_results

# Saving to square dimensions
ggsave("/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_results_100.png",
       plot = corr_results,
       width = 9,  # make wider
       height = 4,  # adjust height
       dpi = 300)

# Saving ggplot object itself
saveRDS(corr_results, file = "/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_results_100.rds")
```

## Graphing One-Step Difference Results
```{r}
# Combining results for both outcomes
results <- rbind(age_DR_results, pfac_DR_results, int_DR_results, ext_DR_results)

# Reorder the x-axis ticks
results$Type <- factor(results$Type,
                        levels = c("Structural vs. Base", "Functional vs. Base", "Both vs. Base"))

# Setting order of boxes
results$ScoreType <- factor(results$ScoreType,
                            levels = c("Age", "P-Factor", "Externalizing Score", "Internalizing Score"))

# Graphing Results
diff_results <- ggplot(results, aes(x = Type, y = diff)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(ymin = lCI_diff, ymax = uCI_diff),
                width = 0.2,
                position = position_dodge(width = 0.5)) +
  facet_wrap(~ ScoreType, nrow = 1) +  # or facet_grid(~ ScoreType)
  labs(title = "Ridge Regression One-Step Differences in RBC",
       x = "Comparisons",
       y = "Difference") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust=1)) + 
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") 
diff_results

# Saving to square dimensions
ggsave("/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_results_diff_100.png",
       plot = diff_results,
       width = 9,  # make wider
       height = 4,  # adjust height
       dpi = 300)

# Saving ggplot object itself
saveRDS(diff_results, file = "/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_results_diff_100.rds")
```

## Graphing One-Step Ratio Results
```{r}
# Combining results for both outcomes
results <- rbind(age_DR_results, pfac_DR_results, int_DR_results, ext_DR_results)

# Reorder the x-axis ticks
results$Type <- factor(results$Type,
                        levels = c("Structural vs. Base", "Functional vs. Base", "Both vs. Base"))

# Setting order of boxes
results$ScoreType <- factor(results$ScoreType,
                            levels = c("Age", "P-Factor", "Externalizing Score", "Internalizing Score"))

# Graphing Results
ratio_results <- ggplot(results, aes(x = Type, y = ratio)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  geom_errorbar(aes(ymin = lCI_ratio, ymax = uCI_ratio),
                width = 0.2,
                position = position_dodge(width = 0.5)) +
  facet_wrap(~ ScoreType, nrow = 1) +  # or facet_grid(~ ScoreType)
  labs(title = "Ridge Regression One-Step Ratios in RBC",
       x = "Comparisons",
       y = "Ratio") +
  theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust=1)) + 
  geom_hline(yintercept = 1, linetype = "dashed", color = "black") 
ratio_results

# Saving to square dimensions
ggsave("/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_results_ratio_100.png",
       plot = ratio_results,
       width = 9,  # make wider
       height = 4,  # adjust height
       dpi = 300)

# Saving ggplot object itself
saveRDS(ratio_results, file = "/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_results_ratio_100.rds")
```



# Storing Extra Information

## Creating a Table for Correlation Values Across Splits
```{r}
# Externalizing Score Table
ext_kable = ext_result[[1]] %>%
  arrange(stat, label, split) %>%   # sort by stat, then label, then split
  select(stat, label, split, estimates, lower_bounds, upper_bounds) %>% 
  kable(caption = "Externalizing Score Estimates and Confidence Bounds by Stat, Label, and Split (Ridge Regression)",
        digits = 3, align = "c")

# Internalizing Score Table
int_kable = int_result[[1]] %>%
  arrange(stat, label, split) %>%   # sort by stat, then label, then split
  select(stat, label, split, estimates, lower_bounds, upper_bounds) %>% 
  kable(caption = "Internalizing Score Estimates and Confidence Bounds by Stat, Label, and Split (Ridge Regression)",
        digits = 3, align = "c")

# Age Score Table
age_kable = age_result[[1]] %>%
  arrange(stat, label, split) %>%   # sort by stat, then label, then split
  select(stat, label, split, estimates, lower_bounds, upper_bounds) %>% 
  kable(caption = "Age Estimates and Confidence Bounds by Stat, Label, and Split (Ridge Regressiont)",
        digits = 3, align = "c")


# P-Factor Table
pfac_kable = pfac_result[[1]] %>%
  arrange(stat, label, split) %>%   # sort by stat, then label, then split
  select(stat, label, split, estimates, lower_bounds, upper_bounds) %>% 
  kable(caption = "P-Factor Score Estimates and Confidence Bounds by Stat, Label, and Split (Ridge Regression)",
        digits = 3, align = "c")

# Saving tables
save_kable(ext_kable, "/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_Externalizing_Table_100.html")
save_kable(int_kable, "/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_Internalizing_Table_100.html")
save_kable(age_kable, "/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_Age_Table_100.html")
save_kable(pfac_kable, "/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_PFactor_Table_100.html")
```

## Creating a Table for OS Difference/Ratio Values Across Splits
```{r}
# Externalizing Score Table
ext_kable = ext_result[[2]] %>%
  arrange(Type, split) %>%   # sort by stat, then label, then split
  select(outcome, Type, split, ratio, lCI_ratio, uCI_ratio, diff, lCI_diff, uCI_diff) %>% 
  kable(caption = "OS Differences/Ratios and Confidence Bounds for Externalizing Score by Comparison and Split (Ridge Regression)",
        digits = 3, align = "c")

# Internalizing Score Table
int_kable = int_result[[2]] %>%
  arrange(Type, split) %>%   # sort by stat, then label, then split
  select(outcome, Type, split, ratio, lCI_ratio, uCI_ratio, diff, lCI_diff, uCI_diff) %>% 
  kable(caption = "OS Differences/Ratios and Confidence Bounds for Internalizing Score by Comparison and Split (Ridge Regression)",
        digits = 3, align = "c")

# Age Score Table
age_kable = age_result[[2]] %>%
  arrange(Type, split) %>%   # sort by stat, then label, then split
  select(outcome, Type, split, ratio, lCI_ratio, uCI_ratio, diff, lCI_diff, uCI_diff) %>% 
  kable(caption = "OS Differences/Ratios and Confidence Bounds for Age by Comparison and Split (Ridge Regression)",
        digits = 3, align = "c")

# P-Factor Table
pfac_kable = pfac_result[[2]] %>%
  arrange(Type, split) %>%   # sort by stat, then label, then split
  select(outcome, Type, split, ratio, lCI_ratio, uCI_ratio, diff, lCI_diff, uCI_diff) %>% 
  kable(caption = "OS Differences/Ratios and Confidence Bounds for P-Factor by Comparison and Split (Ridge Regression)",
        digits = 3, align = "c")

# Saving tables
save_kable(ext_kable, "/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_Externalizing_DR_Table_100.html")
save_kable(int_kable, "/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_Internalizing_DR_Table_100.html")
save_kable(age_kable, "/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_Age_DR_Table_100.html")
save_kable(pfac_kable, "/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_PFactor_DR_Table_100.html")
```

# Creating RBC Results Graphs 

## Graphing Function 
```{r}
# Making a graphing function
makeGraph <- function(graph1, graph2){
  # Adjusting graphs
  graph1 <- graph1 + theme(
    axis.title.x = element_text(margin = margin(t = 8)),
    legend.title = element_text(size = 14),
    legend.text  = element_text(size = 12),
    legend.key.size = unit(1.2, "lines")
  )
  
  graph2 <- graph2 + theme(
    axis.title.x = element_text(margin = margin(t = 8)),
    legend.title = element_text(size = 14),
    legend.text  = element_text(size = 12),
    legend.key.size = unit(1.2, "lines")
  )
  
  # Extracting the legend
  shared_legend <- get_legend(
    graph1 +
      guides(color = guide_legend(
        override.aes = list(
          shape = NA,      # no symbols
          linetype = 1,    # solid line
          size = 1.5       # thicker line for visibility
        )
      )) +
      theme(
        legend.position = "right",
        legend.justification = "center",
        legend.title = element_text(size = 14),
        legend.text  = element_text(size = 12)
      )
  )
    
  # Remove legends from plots
  graph1_nolegend <- graph1 + theme(legend.position = "none")
  graph2_nolegend <- graph2 + theme(legend.position = "none")
  
  # Stack plots and place legend with controlled width
  final_fig <- plot_grid(
    plot_grid(graph1_nolegend, graph2_nolegend, ncol = 1, labels = c("A", "B")),
    shared_legend,
    ncol = 2,
    rel_widths = c(1, 0.175)  # Increase 0.15 â†’ 0.175 to move legend farther right
  )
  
  # Returning the final figure
  return(final_fig)
}
```

## RBC Correlation Graph
```{r}
# Reading in graphs for total analysis
RBCTot100 <- readRDS("/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_results_100.rds")
RFTot100 <- readRDS("/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RF_results_100.rds")

# Turning RF graph to have triangles
RFTot100$layers[[1]] <- NULL
RFTot100 <- RFTot100 + geom_point(position = position_dodge(width = 0.5), 
             size = 3, 
             shape = 17)

# Setting y limits
RBCTot100 <- RBCTot100 + ylim(-0.1, 0.9)
RFTot100 <- RFTot100 + ylim(-0.1, 0.9)

# Running the function
final_fig <- makeGraph(RBCTot100, RFTot100)
final_fig

ggsave("RBC_correlation_comparison.png", final_fig, width = 10, height = 8, dpi = 300, bg = "white")

# save pdf for journal submission
ggsave("Fig4.pdf", final_fig, width = 10, height = 8, device = cairo_pdf)
```

## RBC Difference Graph
```{r}
# Reading in graphs for total analysis
RBCTot100_Diff <- readRDS("/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_results_diff_100.rds")
RFTot100_Diff <- readRDS("/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RF_results_diff_100.rds")

# Turning RF graph to have triangles
RFTot100_Diff$layers[[1]] <- NULL
RFTot100_Diff <- RFTot100_Diff + geom_point(position = position_dodge(width = 0.5), 
             size = 3, 
             shape = 17)

# Setting y limits
RBCTot100_Diff <- RBCTot100_Diff + ylim(-0.22, 0.55)
RFTot100_Diff <- RFTot100_Diff + ylim(-0.22, 0.55)

# Running the function
final_fig <- makeGraph(RBCTot100_Diff, RFTot100_Diff)
final_fig

ggsave("RBC_difference_comparison.png", final_fig, width = 10, height = 8, dpi = 300, bg = "white")

# save pdf for journal submission
ggsave("Fig5.pdf", final_fig, width = 10, height = 8, device = cairo_pdf)
```

## RBC Ratio Graph
```{r}
# Reading in graphs for total analysis
RBCTot100_Ratio <- readRDS("/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RR_results_ratio_100.rds")
RFTot100_Ratio <- readRDS("/media/disk2/multivariateBWAS/ishaan_bwas/RBC_RF_results_ratio_100.rds")

# Turning RF graph to have triangles
RFTot100_Ratio$layers[[1]] <- NULL
RFTot100_Ratio <- RFTot100_Ratio + geom_point(position = position_dodge(width = 0.5), 
             size = 3, 
             shape = 17)

# Log Scaling the graphs
RBCTot100_Ratio <- RBCTot100_Ratio + scale_y_log10()
RFTot100_Ratio <- RFTot100_Ratio + scale_y_log10()

# Setting y limits
RBCTot100_Ratio <- RBCTot100_Ratio + ylim(1e-06, 2e+01)
RFTot100_Ratio <- RFTot100_Ratio + ylim(1e-06, 2e+01)

# Running the function
final_fig <- makeGraph(RBCTot100_Ratio, RFTot100_Ratio)
final_fig

ggsave("RBC_ratio_comparison.png", final_fig, width = 10, height = 8, dpi = 300, bg = "white")

# save pdf for journal submission
ggsave("FigS6.pdf", final_fig, width = 10, height = 8, device = cairo_pdf)
```

## HBN Correlation Graph
```{r}
# Reading in graphs for total analysis
RRHBN250 <- readRDS("/media/disk2/multivariateBWAS/ishaan_bwas/HBN_RR_results_250.rds")
RFHBN250 <- readRDS("/media/disk2/multivariateBWAS/ishaan_bwas/HBN_RF_results_250.rds")

# Turning RF graph to have triangles
RFHBN250$layers[[1]] <- NULL
RFHBN250 <- RFHBN250 + geom_point(position = position_dodge(width = 0.5), 
             size = 3, 
             shape = 17)

# Setting y limits
RRHBN250 <- RRHBN250 + ylim(-0.2, 1.0)
RFHBN250 <- RFHBN250 + ylim(-0.2, 1.0)

# Running the function
final_fig <- makeGraph(RRHBN250, RFHBN250)
final_fig

ggsave("HBN_correlation_comparison.png", final_fig, width = 10, height = 8, dpi = 300, bg = "white")

# save pdf for journal submission
ggsave("FigS7.pdf", final_fig, width = 10, height = 8, device = cairo_pdf)
```

## HBN Difference Graph
```{r}
# Reading in graphs for total analysis
RRHBN250_diff <- readRDS("/media/disk2/multivariateBWAS/ishaan_bwas/HBN_RR_results_diff_250.rds")
RFHBN250_diff <- readRDS("/media/disk2/multivariateBWAS/ishaan_bwas/HBN_RF_results_diff_250.rds")

# Turning RF graph to have triangles
RFHBN250_diff$layers[[1]] <- NULL
RFHBN250_diff <- RFHBN250_diff + geom_point(position = position_dodge(width = 0.5), 
             size = 3, 
             shape = 17)

# Setting y limits
df <- RRHBN250_diff$data
df_trunc <- df %>%
  mutate(lCI_diff = pmax(lCI_diff, -1),
         uCI_diff = pmin(uCI_diff,  1))
RRHBN250_diff <- RRHBN250_diff %+% df_trunc # rebuild ggplot
RRHBN250_diff <- RRHBN250_diff  + ylim(-1, 1.0)
RFHBN250_diff <- RFHBN250_diff + ylim(-1, 1.0)

# Running the function
final_fig <- makeGraph(RRHBN250_diff, RFHBN250_diff)
final_fig

ggsave("HBN_difference_comparison.png", final_fig, width = 10, height = 8, dpi = 300, bg = "white")

# save pdf for journal submission
ggsave("FigS8.pdf", final_fig, width = 10, height = 8, device = cairo_pdf)
```

## HBN Ratio Graph
```{r}
# Reading in graphs for total analysis
RRHBN250_ratio <- readRDS("/media/disk2/multivariateBWAS/ishaan_bwas/HBN_RR_results_ratio_250.rds")
RFHBN250_ratio <- readRDS("/media/disk2/multivariateBWAS/ishaan_bwas/HBN_RF_results_ratio_250.rds")

# Turning RF graph to have triangles
RFHBN250_ratio$layers[[1]] <- NULL
RFHBN250_ratio <- RFHBN250_ratio + geom_point(position = position_dodge(width = 0.5), 
             size = 3, 
             shape = 17)

# Log Scaling the graphs
RRHBN250_ratio <- RRHBN250_ratio + scale_y_log10()
RFHBN250_ratio <- RFHBN250_ratio + scale_y_log10()

# Setting y limits
# RRHBN250_ratio <- RRHBN250_ratio + ylim(-2, 2.0)
# RFHBN250_ratio <- RFHBN250_ratio + ylim(-2, 2.0)

# Running the function
final_fig <- makeGraph(RRHBN250_ratio, RFHBN250_ratio)
final_fig

ggsave("HBN_ratio_comparison.png", final_fig, width = 10, height = 8, dpi = 300, bg = "white")
```

